{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqVcc8rbdKxmYQpD1dyZtl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumyaa2005/CyberSecurity-Assignment-2/blob/main/CS_Project2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAP 1: Inadequate Cookie Analysis**"
      ],
      "metadata": {
        "id": "TlRNj6_b9RHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem:** The research paper highlights stateful tracking (like HTTP Cookies) is common, but conventional detection is a simple \"presence\" check. This lacks context on the cookie's security design.\n",
        "\n",
        "**Improvement:** Implement a **Cookie Hygiene Score (CHS)** to quantify the security of a cookie based on set attributes (`Secure`, `HttpOnly`, `SameSite`) and penalize for excessive lifespan.\n",
        "\n"
      ],
      "metadata": {
        "id": "-WP2OF9Z9cUG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# --- Core Functions (CHS Logic) ---\n",
        "\n",
        "ATTRS = [\"secure\", \"httponly\", \"samesite\"]\n",
        "\n",
        "def parse_set_cookie(header):\n",
        "    # Parses the raw Set-Cookie header string\n",
        "    # ... [function body as provided previously] ...\n",
        "    # Simplified for output:\n",
        "    parts = [p.strip() for p in header.split(\";\")]\n",
        "    name, val = parts[0].split(\"=\", 1) if \"=\" in parts[0] else (parts[0], \"\")\n",
        "    flags = {k: False for k in ATTRS}\n",
        "    samesite = None; max_age=None; expires=None\n",
        "    for p in parts[1:]:\n",
        "        kv = p.split(\"=\", 1)\n",
        "        k = kv[0].strip().lower()\n",
        "        v = kv[1].strip().lower() if len(kv)==2 else True\n",
        "        if k in (\"secure\",\"httponly\"): flags[k]=True\n",
        "        elif k==\"samesite\": flags[\"samesite\"]=True; samesite=v\n",
        "        elif k==\"max-age\": max_age = int(v) if v.isdigit() else None\n",
        "        elif k==\"expires\": expires = v\n",
        "    return {\"name\":name,\"secure\":flags[\"secure\"], \"httponly\":flags[\"httponly\"],\n",
        "            \"samesite\":flags[\"samesite\"], \"samesite_val\":samesite,\n",
        "            \"max_age\":max_age,\"expires\":expires}\n",
        "\n",
        "def cookie_score(df_setcookie):\n",
        "    # Calculates the CHS for each cookie and summarizes by URL\n",
        "    rows = []\n",
        "    for _, r in df_setcookie.iterrows():\n",
        "        meta = parse_set_cookie(r[\"set_cookie_header\"])\n",
        "        score = (1 if meta[\"secure\"] else 0) + (1 if meta[\"httponly\"] else 0) + (1 if meta[\"samesite\"] else 0)\n",
        "        life_pen = 1 if (meta[\"max_age\"] and meta[\"max_age\"] > 60*60*24*30) else 0\n",
        "        rows.append({**meta, \"url\": r[\"url\"], \"score\": score - life_pen})\n",
        "    out = pd.DataFrame(rows)\n",
        "    chs = out.groupby(\"url\")[\"score\"].agg([\"mean\",\"median\",\"count\"]).reset_index().rename(\n",
        "        columns={\"mean\":\"chs_mean\",\"median\":\"chs_med\",\"count\":\"cookie_count\"})\n",
        "    return chs, out\n",
        "\n",
        "# --- Execution and Sample Data ---\n",
        "data = {\n",
        "    \"url\": [\"malicious.com\", \"malicious.com\", \"benign.com\", \"benign.com\"],\n",
        "    \"set_cookie_header\": [\n",
        "        \"SessionID=abc; Secure; HttpOnly; Max-Age=3600\",    # Good Security, Short Life -> Score 2\n",
        "        \"tracking_id=xyz; Max-Age=31536000\",              # No Security, Long Life (Penalty) -> Score -1\n",
        "        \"SID=123; HttpOnly; SameSite=Lax\",                 # Good Security, No Max-Age -> Score 2\n",
        "        \"AdID=123; Max-Age=86400; Secure\"                 # Secure, Short Life -> Score 1\n",
        "    ]\n",
        "}\n",
        "df_input = pd.DataFrame(data)\n",
        "chs_summary, df_detailed = cookie_score(df_input)\n",
        "\n",
        "# Print results\n",
        "print(\"--- Cookie Hygiene Score (CHS) Summary per URL ---\")\n",
        "print(chs_summary)"
      ],
      "metadata": {
        "id": "4Q9sqCop89Ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd36bd88-f067-4e30-f605-5ab9ce1bf6ad"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Cookie Hygiene Score (CHS) Summary per URL ---\n",
            "             url  chs_mean  chs_med  cookie_count\n",
            "0     benign.com       1.5      1.5             2\n",
            "1  malicious.com       0.5      0.5             2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAP 2: Binary Navigator Fingerprinting Detection**\n"
      ],
      "metadata": {
        "id": "Zj9TXFHZ9qNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem:** Navigator fingerprinting is common, but the paper notes it only tracks **presence** and doesn't profile *which properties* are used. The basic model can't distinguish between a benign query and aggressive fingerprinting.\n",
        "\n",
        "\n",
        "**Improvement:** Extract **Navigator Specific Properties (NSP)** into a feature matrix, quantifying the breadth of properties accessed to identify aggressive fingerprinting attempts."
      ],
      "metadata": {
        "id": "LWUA6P5T92Bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# analysis/extract_navigator.py\n",
        "import pandas as pd\n",
        "\n",
        "# List of key properties to track\n",
        "NAV_KEYS = [\"userAgent\",\"language\",\"languages\",\"platform\",\"deviceMemory\",\n",
        "            \"hardwareConcurrency\",\"plugins\",\"webdriver\",\"userAgentData.brands\",\n",
        "            \"userAgentData.platform\",\"userAgentData.mobile\"]\n",
        "\n",
        "def build_nsp(js_calls_df):  # Assumes input columns: url, api, prop\n",
        "    # Filter for navigator API calls\n",
        "    df = js_calls_df[js_calls_df[\"api\"].str.contains(\"navigator\", case=False, na=False)].copy()\n",
        "    df[\"prop_norm\"] = df[\"prop\"].str.lower()\n",
        "\n",
        "    # Map raw properties to standard buckets\n",
        "    feats = {k.lower():k for k in NAV_KEYS}\n",
        "    df[\"prop_bucket\"] = df[\"prop_norm\"].map(lambda p: next((f for f in feats if f in p), None))\n",
        "\n",
        "    # Pivot to create a URL x Property binary matrix\n",
        "    mat = (df.dropna(subset=[\"prop_bucket\"])\n",
        "             .assign(val=1)\n",
        "             .pivot_table(index=\"url\", columns=\"prop_bucket\", values=\"val\", aggfunc=\"sum\", fill_value=0)\n",
        "             .reset_index())\n",
        "\n",
        "    # Ensure all columns are binary (0 or 1)\n",
        "    for c in [c for c in mat.columns if c!=\"url\"]:\n",
        "        mat[c] = (mat[c] > 0).astype(int)\n",
        "\n",
        "    # Total count of unique navigator keys accessed\n",
        "    mat[\"n_nav_keys\"] = mat.drop(columns=[\"url\"]).sum(axis=1)\n",
        "    return mat"
      ],
      "metadata": {
        "id": "YyfMS8ZE9wmC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAP 3: Lack of Predictive Context (Machine Learning)**"
      ],
      "metadata": {
        "id": "Tt4fdqKdBtlv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem:** Analyzing tracking mechanism presence alone is an unreliable test for classifying a webpage. Security solutions need context to differentiate malicious from benign.\n",
        "\n",
        "**Improvement:** Integrate the extracted quantitative features (CHS, NSP) into a simple machine learning model (Logistic Regression) to establish a baseline for predictive context."
      ],
      "metadata": {
        "id": "ndRv4ih_Gq9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# analysis/build_features.py\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "def train_eval(X, y):\n",
        "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    clf = LogisticRegression(max_iter=200).fit(Xtr, ytr)\n",
        "    proba = clf.predict_proba(Xte)[:,1]\n",
        "    return {\n",
        "        \"AUC\": roc_auc_score(yte, proba),\n",
        "        \"AP\": average_precision_score(yte, proba),\n",
        "        \"coef\": dict(zip(X.columns, clf.coef_[0]))\n",
        "    }"
      ],
      "metadata": {
        "id": "06kit-E8Grb_"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}