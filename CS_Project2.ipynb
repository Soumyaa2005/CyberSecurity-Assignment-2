{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Parse HTTP responses to Cookie Hygiene Score (CHS)"
      ],
      "metadata": {
        "id": "kI1wxuU2HPWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pi1aHUyrHE7P"
      },
      "outputs": [],
      "source": [
        "# analysis/cookie_hygiene.py\n",
        "import re, math, pandas as pd\n",
        "\n",
        "ATTRS = [\"secure\", \"httponly\", \"samesite\"]\n",
        "def parse_set_cookie(header):\n",
        "    parts = [p.strip() for p in header.split(\";\")]\n",
        "    name, val = parts[0].split(\"=\", 1) if \"=\" in parts[0] else (parts[0], \"\")\n",
        "    flags = {k: False for k in ATTRS}\n",
        "    samesite = None; max_age=None; expires=None\n",
        "    for p in parts[1:]:\n",
        "        kv = p.split(\"=\", 1)\n",
        "        k = kv[0].strip().lower()\n",
        "        v = kv[1].strip().lower() if len(kv)==2 else True\n",
        "        if k in (\"secure\",\"httponly\"): flags[k]=True\n",
        "        elif k==\"samesite\": flags[\"samesite\"]=True; samesite=v\n",
        "        elif k==\"max-age\": max_age = int(v) if v.isdigit() else None\n",
        "        elif k==\"expires\": expires = v\n",
        "    return {\"name\":name,\"secure\":flags[\"secure\"],\"httponly\":flags[\"httponly\"],\n",
        "            \"samesite\":flags[\"samesite\"],\"samesite_val\":samesite,\n",
        "            \"max_age\":max_age,\"expires\":expires}\n",
        "\n",
        "def cookie_score(df_setcookie):  # df_setcookie columns: url, set_cookie_header\n",
        "    rows = []\n",
        "    for _, r in df_setcookie.iterrows():\n",
        "        meta = parse_set_cookie(r[\"set_cookie_header\"])\n",
        "        score = (1 if meta[\"secure\"] else 0) + (1 if meta[\"httponly\"] else 0) + (1 if meta[\"samesite\"] else 0)\n",
        "        # expiry weighting: very long lifetimes penalized (tracking risk)\n",
        "        life_pen = 1 if (meta[\"max_age\"] and meta[\"max_age\"]>60*60*24*30) else 0\n",
        "        rows.append({**meta, \"url\": r[\"url\"], \"score\": score - life_pen})\n",
        "    out = pd.DataFrame(rows)\n",
        "    chs = out.groupby(\"url\")[\"score\"].agg([\"mean\",\"median\",\"count\"]).reset_index().rename(\n",
        "        columns={\"mean\":\"chs_mean\",\"median\":\"chs_med\",\"count\":\"cookie_count\"})\n",
        "    return chs, out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Navigator feature usage (NSP)"
      ],
      "metadata": {
        "id": "SiI_il7nHTH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# analysis/extract_navigator.py\n",
        "import pandas as pd\n",
        "\n",
        "NAV_KEYS = [\"userAgent\",\"language\",\"languages\",\"platform\",\"deviceMemory\",\n",
        "            \"hardwareConcurrency\",\"plugins\",\"webdriver\",\"userAgentData.brands\",\n",
        "            \"userAgentData.platform\",\"userAgentData.mobile\"]\n",
        "\n",
        "def build_nsp(js_calls_df):  # columns: url, api, prop\n",
        "    df = js_calls_df[js_calls_df[\"api\"].str.contains(\"navigator\", case=False, na=False)].copy()\n",
        "    df[\"prop_norm\"] = df[\"prop\"].str.lower()\n",
        "    feats = {k.lower():k for k in NAV_KEYS}\n",
        "    df[\"prop_bucket\"] = df[\"prop_norm\"].map(lambda p: next((f for f in feats if f in p), None))\n",
        "    mat = (df.dropna(subset=[\"prop_bucket\"])\n",
        "             .assign(val=1)\n",
        "             .pivot_table(index=\"url\", columns=\"prop_bucket\", values=\"val\", aggfunc=\"sum\", fill_value=0)\n",
        "             .reset_index())\n",
        "    # binary presence\n",
        "    for c in [c for c in mat.columns if c!=\"url\"]:\n",
        "        mat[c] = (mat[c] > 0).astype(int)\n",
        "    mat[\"n_nav_keys\"] = mat.drop(columns=[\"url\"]).sum(axis=1)\n",
        "    return mat\n"
      ],
      "metadata": {
        "id": "KdIbGHVLHK8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple model & ablation"
      ],
      "metadata": {
        "id": "nChQcsP6HbDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# analysis/build_features.py\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "def train_eval(X, y):\n",
        "    Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    clf = LogisticRegression(max_iter=200).fit(Xtr, ytr)\n",
        "    proba = clf.predict_proba(Xte)[:,1]\n",
        "    return {\n",
        "        \"AUC\": roc_auc_score(yte, proba),\n",
        "        \"AP\": average_precision_score(yte, proba),\n",
        "        \"coef\": dict(zip(X.columns, clf.coef_[0]))\n",
        "    }\n"
      ],
      "metadata": {
        "id": "nujw4R-nHhVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crawl (baseline vs EASP)"
      ],
      "metadata": {
        "id": "_mCxPO6vHrUt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}